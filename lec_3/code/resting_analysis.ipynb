{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line is necessary to have interactive plots. In other case, all plots will be inline (and not interactive)\n",
    "%matplotlib qt \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne_bids import BIDSPath, read_raw_bids # you have to install mne_bids library with pip install mne-bids\n",
    "from mne.channels import make_standard_montage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data (in BIDS format)\n",
    "\n",
    "The data are from the **\"EEG Resting state EEG with closed eyes and open eyes in females from 60 to 80 years old database\"** that can be found here [https://openneuro.org/datasets/ds005420/versions/1.0.0].\n",
    "\n",
    "More on the data can be found here:\n",
    "1. Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., HÃ¶chenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A. and Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software 4: (1896). https://doi.org/10.21105/joss.01896\n",
    "\n",
    "2. Pernet, C. R., Appelhoff, S., Gorgolewski, K. J., Flandin, G., Phillips, C., Delorme, A., Oostenveld, R. (2019). EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Scientific Data, 6, 103. https://doi.org/10.1038/s41597-019-0104-81.\n",
    "\n",
    "In order to be able to load the EEG recordings of the subjects you need to define the correct path in the ```bids_root``` variable and the corresponding subject number in the ```subject``` variable.\n",
    "\n",
    "The result of the following block of code is two data arrays:\n",
    "1. ```raw_open``` with the raw EEG recordings while the subject has their eyes open\n",
    "2. ```raw_closed``` with the raw EEG recordings while the subject has their eyes closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/koutras/DataBases/Resting State Database/sub-10/eeg/sub-10_task-oa_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading channel info from /home/koutras/DataBases/Resting State Database/sub-10/eeg/sub-10_task-oa_channels.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Extracting EDF parameters from /home/koutras/DataBases/Resting State Database/sub-10/eeg/sub-10_task-oc_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading channel info from /home/koutras/DataBases/Resting State Database/sub-10/eeg/sub-10_task-oc_channels.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 100499  =      0.000 ...   200.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3097305/3871895015.py:21: RuntimeWarning: Did not find any events.tsv associated with sub-10_task-oa.\n",
      "\n",
      "The search_str was \"/home/koutras/DataBases/Resting State Database/sub-10/**/eeg/sub-10*events.tsv\"\n",
      "  raw_open = read_raw_bids(bids_path_open, verbose=True)\n",
      "/tmp/ipykernel_3097305/3871895015.py:21: RuntimeWarning: Unable to map the following column(s) to to MNE:\n",
      "sex (subject sex): None\n",
      "  raw_open = read_raw_bids(bids_path_open, verbose=True)\n",
      "/tmp/ipykernel_3097305/3871895015.py:22: RuntimeWarning: Did not find any events.tsv associated with sub-10_task-oc.\n",
      "\n",
      "The search_str was \"/home/koutras/DataBases/Resting State Database/sub-10/**/eeg/sub-10*events.tsv\"\n",
      "  raw_closed = read_raw_bids(bids_path_closed, verbose=True)\n",
      "/tmp/ipykernel_3097305/3871895015.py:22: RuntimeWarning: Unable to map the following column(s) to to MNE:\n",
      "sex (subject sex): None\n",
      "  raw_closed = read_raw_bids(bids_path_closed, verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 96499  =      0.000 ...   192.998 secs...\n",
      "Sampling rate: 500.0 Hz\n",
      "Number of channels: 20\n",
      "Channel names: ['EEG Fp1-A1A2', 'EEG Fp2-A1A2', 'EEG Fz-A1A2', 'EEG F3-A1A2', 'EEG F4-A1A2', 'EEG F7-A1A2', 'EEG F8-A1A2', 'EEG Cz-A1A2', 'EEG C3-A1A2', 'EEG C4-A1A2', 'EEG T3-A1A2', 'EEG T4-A1A2', 'EEG Pz-A1A2', 'EEG P3-A1A2', 'EEG P4-A1A2', 'EEG T5-A1A2', 'EEG T6-A1A2', 'EEG O1-A1A2', 'EEG O2-A1A2', 'EEG LOC-ROC']\n"
     ]
    }
   ],
   "source": [
    "# Set path to BIDS dataset\n",
    "bids_root = \"/home/koutras/DataBases/Resting State Database/\"  # Path to the root of the BIDS dataset\n",
    "subject = \"1\"  # Replace with assigned subject number (without \"sub-\" prefix)\n",
    "\n",
    "# Define BIDS paths for eyes open and eyes closed conditions\n",
    "bids_path_open = BIDSPath(\n",
    "    subject=subject,\n",
    "    task=\"oa\",  # 'oa' is the task code for eyes open\n",
    "    datatype=\"eeg\",\n",
    "    root=bids_root\n",
    ")\n",
    "\n",
    "bids_path_closed = BIDSPath(\n",
    "    subject=subject,\n",
    "    task=\"oc\",  # 'oc' is the task code for eyes closed\n",
    "    datatype=\"eeg\",\n",
    "    root=bids_root\n",
    ")\n",
    "\n",
    "# Load the data using BIDS paths\n",
    "raw_open = read_raw_bids(bids_path_open, verbose=True)\n",
    "raw_closed = read_raw_bids(bids_path_closed, verbose=True)\n",
    "\n",
    "# Then load the data into memory\n",
    "raw_open.load_data()\n",
    "raw_closed.load_data()\n",
    "\n",
    "\n",
    "# The BIDS reader automatically loads metadata like channel types, sampling frequency, etc.\n",
    "print(f\"Sampling rate: {raw_open.info['sfreq']} Hz\")\n",
    "print(f\"Number of channels: {len(raw_open.ch_names)}\")\n",
    "print(f\"Channel names: {raw_open.ch_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will rename the channel names into something more typical following the 10-20 international system. In addition we will also rename the EOG channel (this will not be used in our analysis, but feel free to use it if you want to further process the data) into something more standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from your channel names to standard 10-20 names\n",
    "ch_mapping = {\n",
    "    'EEG Fp1-A1A2': 'Fp1',\n",
    "    'EEG Fp2-A1A2': 'Fp2',\n",
    "    'EEG Fz-A1A2': 'Fz',\n",
    "    'EEG F3-A1A2': 'F3',\n",
    "    'EEG F4-A1A2': 'F4',\n",
    "    'EEG F7-A1A2': 'F7',\n",
    "    'EEG F8-A1A2': 'F8',\n",
    "    'EEG Cz-A1A2': 'Cz',\n",
    "    'EEG C3-A1A2': 'C3',\n",
    "    'EEG C4-A1A2': 'C4',\n",
    "    'EEG T3-A1A2': 'T7',  # or 'T7' in newer naming\n",
    "    'EEG T4-A1A2': 'T8',  # or 'T8' in newer naming\n",
    "    'EEG Pz-A1A2': 'Pz',\n",
    "    'EEG P3-A1A2': 'P3',\n",
    "    'EEG P4-A1A2': 'P4',\n",
    "    'EEG T5-A1A2': 'P7',  # or 'P7' in newer naming\n",
    "    'EEG T6-A1A2': 'P8',  # or 'P8' in newer naming\n",
    "    'EEG O1-A1A2': 'O1',\n",
    "    'EEG O2-A1A2': 'O2',\n",
    "}\n",
    "\n",
    "# First, explicitly set the channel type for the EOG channel\n",
    "raw_open.set_channel_types({'EEG LOC-ROC': 'eog'})\n",
    "raw_closed.set_channel_types({'EEG LOC-ROC': 'eog'})\n",
    "\n",
    "# Now rename just the EEG channels\n",
    "raw_open.rename_channels(ch_mapping)\n",
    "raw_closed.rename_channels(ch_mapping)\n",
    "\n",
    "# Set the montage with on_missing='ignore' to ignore the EOG channel\n",
    "montage = make_standard_montage('standard_1020')\n",
    "raw_open.set_montage(montage, on_missing='ignore')\n",
    "raw_closed.set_montage(montage, on_missing='ignore')\n",
    "\n",
    "# Plot to verify channel locations\n",
    "fig = raw_open.plot_sensors(show_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot our two data structures, eyes open / eyes closed using interactive plots of MNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x799bf08f3c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_closed.plot()\n",
    "raw_open.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Preprocessing\n",
    "\n",
    "In this part we present the basic workflow of the signal pre-processing, that includes:\n",
    "1. Bandpass filtering keeping frequencies in the range of 1-40Hz (since we don't really care for higher frequencies in our analysis).\\\n",
    "2. Notch filtering the mains frequency (50Hz) for Europe.\n",
    "\n",
    "Note that since we are particularly interested in analyzing the brain activity inside the alpha (8-13Hz) band, we could have band-pass filtered our recordings using lower value for the upper-frequency of the filter (i.e. 30Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# 1. Apply bandpass filter (1-40 Hz)\n",
    "raw_open_filtered = raw_open.copy().filter(l_freq=1, h_freq=40, \n",
    "                                         method='fir', phase='zero',\n",
    "                                         fir_design='firwin')\n",
    "\n",
    "raw_closed_filtered = raw_closed.copy().filter(l_freq=1, h_freq=40, \n",
    "                                             method='fir', phase='zero',\n",
    "                                             fir_design='firwin')\n",
    "\n",
    "# 2. Apply notch filter for line noise (50 Hz)\n",
    "raw_open_filtered.notch_filter(freqs=50, picks='eeg')\n",
    "raw_closed_filtered.notch_filter(freqs=50, picks='eeg')\n",
    "\n",
    "# 3. Identify bad channels\n",
    "# Option 1: Visual inspection\n",
    "raw_open_filtered.plot(duration=30, n_channels=20)  # Look for bad channels\n",
    "raw_closed_filtered.plot(duration=30, n_channels=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Analysis\n",
    "\n",
    "In this part, we perform the spectral analysis of the signals. \n",
    "\n",
    "1. First we plot the Power Spectral Density (PSD) of the signals in both conditions (eyes open/eyes closed) using ```fmin=0Hz``` to ```fmax=48Hz``` for each channel. Finally we plot the **average** PSD using all channels for each condition.\n",
    "2. We make a selection of EEG electrodes near the region of interest. Since we are interested for alpha activity which is located at the back of the brain (occipital), we don't want the signal to analyze and plot to be \"contaminated\" by brain activity not directly related to the eyes open/closed experiment. For this, we consider only the parietal and occipital electrodes and in particular the P3, P4, Pz, O1 and O2 and plot the PSD for each one of these.\n",
    "3. Then, we plot the topography of the power as this is distributed on the electrode space (topographic plot) in different basic frequency bands (delta - theta - alpha - beta - gamma). This is very informative, as it can reveal the area that significant PSD is located (we expect this area to be at the back of the head for the eyes closed condition).\n",
    "4. Finally we show each channel's PSD relative to its position on the head. This plot is interactive, as we can click on any PSD and have it zoomed in a separate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 4.096 (s)\n",
      "Plotting power spectral density (dB=True).\n",
      "Effective window size : 4.096 (s)\n",
      "Plotting power spectral density (dB=True).\n",
      "Plotting power spectral density (dB=True).\n",
      "Plotting power spectral density (dB=True).\n"
     ]
    }
   ],
   "source": [
    "# First we estimate and then plot the mean PSD across all electrodes for both the conditions \n",
    "spectrum_open = raw_open_filtered.compute_psd(fmin=0, fmax = 48)\n",
    "spectrum_open.plot(average=True, picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "\n",
    "spectrum_closed = raw_closed_filtered.compute_psd(fmin=0, fmax = 48)\n",
    "spectrum_closed.plot(average=True, picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "\n",
    "# Next we define a region of interest on the electrode space and plot the power of each electrode\n",
    "channel_sel = ['O1', 'O2', 'P3', 'P4', 'Pz']\n",
    "spectrum_open.plot(picks=channel_sel, exclude=\"bads\", amplitude=False)\n",
    "\n",
    "spectrum_closed.plot(picks=channel_sel, exclude=\"bads\", amplitude=False)\n",
    "\n",
    "# Topographic plots of the distribution of the power on the electrode space for both conditions.\n",
    "spectrum_open.plot_topomap()\n",
    "spectrum_closed.plot_topomap()\n",
    "\n",
    "# Finally we plot all channels' PSD plots in a way relative to their position on the head\n",
    "spectrum_open.plot_topo()\n",
    "spectrum_closed.plot_topo()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this part, we continue estimating the PSD of the signals for both conditions, using specific parameters in the calculation of the PSD, using the Welch method. Then, we plot the PSD of the O1, O2 channels for both conditions on a plot that has highlighted the alpha frequency band (8-13Hz). These plors don't differentiate from the previous that rely solely on MNE's functions and methods, but with a little extra cost programmatically, we can shape the plots in the way we want (to be more informative).\n",
    "\n",
    "2. We calculate the mean power for each channel in both cases, but only **inside the alpha band** and we print the power ratio for each channel as\n",
    "\n",
    "3. Finally we plot alpha power topography for eyes open, eyes closed as well as the power_ratio for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 4.096 (s)\n",
      "Effective window size : 4.096 (s)\n",
      "Alpha Power (8-13 Hz):\n",
      "Fp1:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.44x\n",
      "Fp2:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.57x\n",
      "Fz:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.63x\n",
      "F3:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.50x\n",
      "F4:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.72x\n",
      "F7:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.35x\n",
      "F8:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.84x\n",
      "Cz:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.12x\n",
      "C3:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.92x\n",
      "C4:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.35x\n",
      "T7:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 1.30x\n",
      "T8:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.04x\n",
      "Pz:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.98x\n",
      "P3:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.60x\n",
      "P4:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 2.67x\n",
      "P7:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 3.57x\n",
      "P8:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 3.01x\n",
      "O1:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 5.27x\n",
      "O2:\n",
      "  Eyes Open: 0.00 ÂµVÂ²/Hz\n",
      "  Eyes Closed: 0.00 ÂµVÂ²/Hz\n",
      "  Ratio (Closed/Open): 3.79x\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate PSD using Welch's method\n",
    "\n",
    "\n",
    "# Define frequency range\n",
    "fmin, fmax = 0.5, 45\n",
    "\n",
    "# Calculate PSD for both conditions\n",
    "psd_open, freqs = raw_open_filtered.compute_psd(method='welch', fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "\n",
    "psd_closed, freqs = raw_closed_filtered.compute_psd(method='welch', fmin=fmin, fmax=fmax).get_data(return_freqs=True)\n",
    "\n",
    "\n",
    "# 2. Plot PSD comparison\n",
    "# Select occipital and parietal channels where alpha is typically most prominent\n",
    "picks = ['O1', 'O2']\n",
    "pick_idx = [raw_open_filtered.ch_names.index(ch) for ch in picks]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Plot individual channels\n",
    "for idx, ch_idx in enumerate(pick_idx):\n",
    "    plt.semilogy(freqs, psd_open[ch_idx], \n",
    "                label=f'{raw_open_filtered.ch_names[ch_idx]} (Open)', \n",
    "                alpha=0.5, linestyle='--')\n",
    "    plt.semilogy(freqs, psd_closed[ch_idx], \n",
    "                label=f'{raw_closed_filtered.ch_names[ch_idx]} (Closed)', \n",
    "                alpha=0.5)\n",
    "\n",
    "# Highlight alpha band\n",
    "plt.axvspan(8, 13, color='yellow', alpha=0.2, label='Alpha Band (8-13 Hz)')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power Spectral Density (ÂµVÂ²/Hz)')\n",
    "plt.title('Power Spectrum: Eyes Open vs Eyes Closed')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.xlim(fmin, 30)  # Limit x-axis to 30 Hz for better visualization\n",
    "plt.show()\n",
    "\n",
    "# 3. Calculate alpha band power\n",
    "alpha_band = (8, 13)\n",
    "alpha_idx = np.logical_and(freqs >= alpha_band[0], freqs <= alpha_band[1])\n",
    "\n",
    "# Extract alpha power for all channels\n",
    "alpha_power_open = np.mean(psd_open[:, alpha_idx], axis=1)\n",
    "alpha_power_closed = np.mean(psd_closed[:, alpha_idx], axis=1)\n",
    "alpha_ratio = alpha_power_closed / alpha_power_open\n",
    "\n",
    "# Print alpha power for each channel\n",
    "print(\"Alpha Power (8-13 Hz):\")\n",
    "for i, ch_name in enumerate(raw_open_filtered.ch_names[:-1]):\n",
    "    print(f\"{ch_name}:\")\n",
    "    print(f\"  Eyes Open: {alpha_power_open[i]:.2f} ÂµVÂ²/Hz\")\n",
    "    print(f\"  Eyes Closed: {alpha_power_closed[i]:.2f} ÂµVÂ²/Hz\")\n",
    "    print(f\"  Ratio (Closed/Open): {alpha_ratio[i]:.2f}x\")\n",
    "\n",
    "# 4. Generate topographic maps\n",
    "# Plot alpha power topography for eyes open\n",
    "mne.viz.plot_topomap(alpha_power_open, raw_open_filtered.info, \n",
    "                    show=False, cmap='viridis')\n",
    "plt.title('Alpha Power - Eyes Open')\n",
    "\n",
    "# Plot alpha power topography for eyes closed\n",
    "mne.viz.plot_topomap(alpha_power_closed, raw_closed_filtered.info, \n",
    "                    show=False, cmap='viridis')\n",
    "plt.title('Alpha Power - Eyes Closed')\n",
    "\n",
    "# Plot ratio of alpha power (closed/open)\n",
    "mne.viz.plot_topomap(alpha_ratio, raw_open_filtered.info, \n",
    "                    show=False, cmap='viridis')\n",
    "plt.title('Alpha Power Ratio (Closed/Open)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Frequency Analysis\n",
    "\n",
    "Here we perform further analysis of our signals using Time Frequency analysis techniques. Since the signal that we examine cannot be considered to be stationary, we want to break it in smaller parts and perform the analysis therein.\n",
    "For this purpose, we take only the electrode 'O1' (but you are more than welcome to analyze any other electrode you like) and we break it into smaller time windows with duration of 2sec (again feel free to play with the duration and see how the results change).\n",
    "Next we perform time-frequency analysis using Wavelet analysis (a common method of multiresolution analysis) inside a range of frequencies 4-30Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "96 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 96 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.2s\n"
     ]
    }
   ],
   "source": [
    "# Time-Frequency Analysis\n",
    "from mne.time_frequency import tfr_morlet\n",
    "\n",
    "# Select a posterior channel where alpha is prominent\n",
    "ch_name = 'O1'\n",
    "ch_idx = raw_open_filtered.ch_names.index(ch_name)\n",
    "\n",
    "# Create epochs for analysis (divide continuous data into 2-second epochs)\n",
    "# This helps visualize time-frequency content over the recording\n",
    "epoch_duration = 2.0  # seconds\n",
    "events_open = mne.make_fixed_length_events(raw_open_filtered, \n",
    "                                         duration=epoch_duration)\n",
    "events_closed = mne.make_fixed_length_events(raw_closed_filtered,\n",
    "                                           duration=epoch_duration)\n",
    "\n",
    "epochs_open = mne.Epochs(raw_open_filtered, events_open, tmin=0, tmax=epoch_duration,\n",
    "                       baseline=None, preload=True, reject=None)\n",
    "epochs_closed = mne.Epochs(raw_closed_filtered, events_closed, tmin=0, tmax=epoch_duration,\n",
    "                         baseline=None, preload=True, reject=None)\n",
    "\n",
    "# Define frequencies of interest\n",
    "freqs = np.arange(4, 30, 1)  # 4-30 Hz in 1 Hz steps\n",
    "n_cycles = freqs / 2.  # Adjust cycles for better time-frequency resolution\n",
    "\n",
    "# Compute time-frequency representation with Morlet wavelets\n",
    "\n",
    "power_open = epochs_open.compute_tfr(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    average=True,\n",
    "    return_itc=False,\n",
    "    decim=3,\n",
    ")\n",
    "power_closed = epochs_closed.compute_tfr(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    average=True,\n",
    "    return_itc=False,\n",
    "    decim=3,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the power of the signals in different frequencies and the different 2sec time intervals, we proceed and plot them. What we would like *ideally* to see is the power to be significantly larger in the alpha band for the eyes closed condition compared to the eyes open condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "# Plot time-frequency representations\n",
    "\n",
    "power_open.plot([ch_idx], baseline=None, mode='mean', \n",
    "               title=f'Time-Frequency Analysis: {ch_name} - Eyes Open',\n",
    "               show=False)\n",
    "\n",
    "power_closed.plot([ch_idx], baseline=None, mode='mean', \n",
    "                 title=f'Time-Frequency Analysis: {ch_name} - Eyes Closed',\n",
    "                 show=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to show a comparative plot of the mean power of the channel we analyze within the frequency band of interest (alpha band 8-13Hz). \n",
    "\n",
    "This plot is different from the previous, as it shows the **mean** power across all epochs (*remember the 2sec blocks we formed earlier?*) for the two different conditions (eyes open/closed). This results in very informative plots as *theoretically* we should see that the power of the occipital channel for the eyes closed condition should be **greater** than the power of the signal in the eyes open condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Plot alpha band time course (power over time)\n",
    "alpha_freqs = np.logical_and(freqs >= 8, freqs <= 13)\n",
    "alpha_idx = np.where(alpha_freqs)[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(power_open.times, np.mean(power_open.data[ch_idx, alpha_idx, :], axis=0),\n",
    "         label='Eyes Open', color='blue')\n",
    "plt.plot(power_closed.times, np.mean(power_closed.data[ch_idx, alpha_idx, :], axis=0),\n",
    "         label='Eyes Closed', color='red')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Alpha Power')\n",
    "plt.title(f'Alpha Power Over Time: {ch_name}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosignals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
